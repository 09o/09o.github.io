<!DOCTYPE html><html lang="en-us"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>ML · 01 | Loading 09o</title><meta name="description"><meta name="generator" content="Loading 09o"><meta name="author" content="09o"><meta name="keywords" content="Hexo, X'new"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1,user-scalable=0"><link rel="stylesheet" type="text/css" href="/styles/screen.css"><link rel="apple-touch-icon" sizes="57x57" href="/images/apple-touch-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/images/apple-touch-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/images/apple-touch-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/images/apple-touch-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/images/apple-touch-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/images/apple-touch-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-180x180.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/images/favicon-96x96.png"><link rel="icon" type="image/png" sizes="160x160" href="/images/favicon-160x160.png"><link rel="icon" type="image/png" sizes="192x192" href="/images/favicon-192x192.png"><meta name="msapplication-TileColor" content="#121315"><meta name="msapplication-TileImage" content="/images/mstile-144x144.png"></head><body itemscope itemtype="https://schema.org/WebPage"><header itemscope itemtype="https://schema.org/WPHeader"><a href="/"><img src="/images/svdb.png" alt="Loading 09o" title="Loading 09o"></a><h1><a href="/" alt="Loading 09o" title="Loading 09o" itemprop="headline">Loading 09o</a></h1><p itemprop="description">Where there is a will, there is a way.</p><nav itemscope itemtype="https://schema.org/SiteNavigationElement"><ul><li itemprop="name"><a href="/" alt="Home" title="Home" itemprop="url">Home</a></li><li itemprop="name"><a href="/archives" alt="Archives" title="Archives" itemprop="url">Archives</a></li><li itemprop="name"><a href="/categories" alt="Categories" title="Categories" itemprop="url">Categories</a></li><li itemprop="name"><a href="/about" alt="About" title="About" itemprop="url">About</a></li></ul></nav><div class="space"></div></header><main itemscope itemtype="https://schema.org/Blog"><article class="full"><h1 itemprop="headline">ML · 01</h1><span class="post-meta">Published on<time itemprop="datePublished" datetime="2017-10-02T22:26:57.000Z"> Tuesday, October 3rd 2017 at 6:26</time><br>Last updated on<time itemprop="dateModified" datetime="2017-10-02T22:26:57.000Z"> Monday, October 16th 2017 at 7:05</time></span><p><img src="http://wx4.sinaimg.cn/large/ee20bc6cgy1fk4nudy0j8j20q40fun3g.jpg" alt="此处输入图片的描述"></p>
<h5 style="text-align:right">Machine Learning - Adrew Ng</h5>


<p>“这是关于我在Coursera上所学课程的学习笔记。仅用作个人记录与参考，如发现错误，感谢指出。”</p>
<h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><p><strong>ML两个定义</strong>：<br>1）Arthur Samuel:”the field of study that gives computer the ability to<a id="more"></a> learn without being explictly programmed.” (older)<br>2) Tom Mitchell [CMU]:”A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P. if its performance at tasks in T, as measured by P. improves with experience E.”</p>
<blockquote>
<p>Example: playing checker.<br>E=the experience of playing many game of checker.<br>T=the task of playing checkers.<br>P=the probability that the program will win the next game.</p>
</blockquote>
<p><strong>监督学习(supervised learning)</strong>；<br>分为：</p>
<ol>
<li><strong>回归问题(regression)</strong>: In aregression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function.<br>&emsp;例：房价预测（因为价格作为大小的函数提供连续输出）；给定一张照片预测年龄…</li>
<li><strong>分类问题(classification)</strong>: In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories.<br>&emsp;例：癌症肿瘤的恶心与良性…</li>
</ol>
<p><strong>无监督学习(unsupervised learning)</strong>: UL allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don’t necessarily know the effect of the variables.<br>UL属于一种<strong>聚类学习</strong>：它是一种学习机制，给出算法大量的数据，要求它找出数据中，蕴含的类型结构。即通过基于数据中的变量之间的关系对数据进行聚类，来导出该结构。<br>例：1）clustering: 收集一万个不同的基因，找到一种自动将其组合成不同变量（如寿命、位置）的相似或相关的组。<br>&emsp;&emsp;2）Non-clusteering: 声音（混乱环境中）</p>
<hr>
<h2 id="模型和代价函数（Model-and-Cost-Function"><a href="#模型和代价函数（Model-and-Cost-Function" class="headerlink" title="模型和代价函数（Model and Cost Function)"></a>模型和代价函数（Model and Cost Function)</h2><p><strong>模型表示(Model Representation)</strong><br>建立符号以供将来使用，其中<strong>x^(i)</strong>表示输入变量，也叫输入功能。【注意：i只是一个索引，不代表x的幂】；<strong>y^(i)</strong>表示输出变量或目标变量。一对（x^(i), y^(i))称为<strong>training example</strong>. 我们将使用数据集来学习，一系列m training examples (x^(i), y^(i));i=1,…,m —— 被称作一个 <strong>training set</strong>.（x, y也可用X,Y表示，其中X=Y=R)</p>
<p><strong><em>监督学习算法的工作方式:</em></strong>（以预测房价为例）<br><img src="http://wx2.sinaimg.cn/mw690/ee20bc6cgy1fk4prwd82uj20et0cfwg8.jpg" alt="此处输入图片的描述"></p>
<p>将训练集中的房屋价格“喂”给学习算法（Training Set –&gt; Learning Algorithm)，这就是学习算法的工作，然后输出一个函数（h)。根据惯例，写为小写 h. 输入是房屋尺寸大小，然后h根据输入的x值来得到y值，因此h是一个从x到y的函数映射。</p>
<blockquote>
<p>h代表hypothesis &lt;假设&gt;，h表示一个函数，记为如下：<img src="http://wx1.sinaimg.cn/mw690/ee20bc6cgy1fk4pzlwpidj20ce09qdh4.jpg" alt="此处输入图片的描述"></p>
</blockquote>
<p><strong>线性回归(linear regression)模型</strong><br>以上例子实际上就是关于单个变量(x)的线性回归。根据x来预测所有的价格函数，同时，对于这种模型有另外一个名称，称作单变量线性回归。单变量是对一个变量的一种特别的表述方式。总而言之，这就是<strong><em>线性回归(linear regression)</em></strong>。</p>
<p><strong><em>Hypothesis</em></strong>:<br><img src="http://wx3.sinaimg.cn/mw690/ee20bc6cgy1fk4q8es9tsj20bd026wem.jpg" alt="此处输入图片的描述"><br>θ(i) - 模型参数(parameters)</p>
<p>在线性回归中，要解决一个最小化问题，所以要写出θ(0),θ(1)的最小化。而且，要这个式子极其小，即h(x)和y之间差异要小，即要减少假设假设的输入与房子真实价格之间的差的平方，记为：(hθ(x)-y)^2. 因为是训练m组数据，所以对所有训练样本进行一个求和，记为：<img src="http://wx1.sinaimg.cn/mw690/ee20bc6cgy1fk4qqipl7mj20ad03gglf.jpg" alt="此处输入图片的描述"><br>实际上要考虑的是：<br><img src="http://wx3.sinaimg.cn/mw690/ee20bc6cgy1fk4qt54715j20co02zt8j.jpg" alt="此处输入图片的描述"><br>因此要尝试尽量减少平均误差，也就是尽量减少其1/2m, 通常是这个数的一半，即：<br><img src="http://wx4.sinaimg.cn/mw690/ee20bc6cgy1fk4qw0197pj20ck0380sk.jpg" alt="此处输入图片的描述"><br><strong>综上</strong>：<br><img src="http://wx4.sinaimg.cn/mw690/ee20bc6cgy1fk4r2cbedrj20ha0380sl.jpg" alt="此处输入图片的描述"><br>这个表达式表示关于θ(0)和θ(1)的最小化过程，这意味着要找到θ(0)和θ(1)的值来使这个表达式(Hypothesis [hθ(x^i)])的值最小。<br>为了是其更明确，我们讲改写这个函数：<br>首先定义一个<strong>代价函数(Cost Function)</strong>:<br><img src="http://wx2.sinaimg.cn/mw690/ee20bc6cgy1fk4rhr97pqj20ig03d745.jpg" alt="此处输入图片的描述"></p>
<p>即：<br><img src="http://wx2.sinaimg.cn/mw690/ee20bc6cgy1fk4rmvq1tmj208102fglo.jpg" alt="此处输入图片的描述"></p>
<p>代价函数也被称为<strong><em>平方误差函数(squared error function)</em></strong>或<strong><em>平方误差代价函数(mean squared error function)</em></strong>. 对于大多数问题，特别是回归问题都是一个合理的选择（<strong>最常用</strong>）。</p>
<p>我们将它简化为如下(这是在θ(0)=0的情况下)：<br><img src="http://wx2.sinaimg.cn/mw690/ee20bc6cgy1fk4royfnfzj20bp0d5763.jpg" alt="此处输入图片的描述"></p>
<p>可以来区别假设函数和代价函数：<br><img src="http://wx1.sinaimg.cn/mw690/ee20bc6cgy1fk4rwyel4sj218g0p0176.jpg" alt="此处输入图片的描述"></p>
<p>运用轮廓图来区别(这是在θ(0)≠0的情况下):<br><img src="http://wx3.sinaimg.cn/mw690/ee20bc6cgy1fk4s3g7d5hj218g0p0k66.jpg" alt="此处输入图片的描述"></p>
<hr>
<p>到这里差不多就是我今天所学的一部分内容了，总的来说，开始难度太大。但是里面有一些小细节还是需要特别注意和记忆的，总之，还有很多需要学习的。</p>
</article></main></body></html>